{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 9194920,
     "sourceType": "datasetVersion",
     "datasetId": 5558666
    }
   ],
   "dockerImageVersionId": 30747,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = '/kaggle/input/data01/data (1).csv'  # Update this path with your actual dataset file\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Encode categorical variables manually\n",
    "def encode_labels(df, column):\n",
    "    labels = df[column].unique()\n",
    "    label_map = {label: idx for idx, label in enumerate(labels)}\n",
    "    df[column] = df[column].map(label_map)\n",
    "    return label_map\n",
    "\n",
    "label_map_team = encode_labels(df, 'Team')\n",
    "label_map_position = encode_labels(df, 'Position')\n",
    "\n",
    "# Features and target\n",
    "X = df[['Team', 'Position']]\n",
    "y = df['win-loss-pct']\n",
    "\n",
    "# Split the data manually\n",
    "def train_test_split(X, y, test_size=0.2, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    split_idx = int(X.shape[0] * (1 - test_size))\n",
    "    train_idx, test_idx = indices[:split_idx], indices[split_idx:]\n",
    "    return X.iloc[train_idx], X.iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Feature scaling manually\n",
    "def standardize(X_train, X_test):\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "    X_train_scaled = (X_train - mean) / std\n",
    "    X_test_scaled = (X_test - mean) / std\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "X_train_scaled, X_test_scaled = standardize(X_train, X_test)\n",
    "\n",
    "# Create and train the neural network\n",
    "model = Sequential([\n",
    "    Dense(50, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(30, activation='relu'),\n",
    "    Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Evaluation metrics\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Show predictions vs true values\n",
    "results = pd.DataFrame({'Actual': y_test.values, 'Predicted': y_pred})\n",
    "print(results.head())\n"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-08-18T06:29:49.376017Z",
     "iopub.execute_input": "2024-08-18T06:29:49.376648Z",
     "iopub.status.idle": "2024-08-18T06:29:59.034388Z",
     "shell.execute_reply.started": "2024-08-18T06:29:49.376611Z",
     "shell.execute_reply": "2024-08-18T06:29:59.033503Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Epoch 1/100\n\u001B[1m 1/29\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m51s\u001B[0m 2s/step - loss: 0.4006",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1723962592.116478     238 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - loss: 0.2432\nEpoch 2/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0527 \nEpoch 3/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0459 \nEpoch 4/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0411 \nEpoch 5/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0416 \nEpoch 6/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0379 \nEpoch 7/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0378 \nEpoch 8/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0350 \nEpoch 9/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0344 \nEpoch 10/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0362 \nEpoch 11/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0362 \nEpoch 12/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0342 \nEpoch 13/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0347 \nEpoch 14/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0331 \nEpoch 15/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0333 \nEpoch 16/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0351 \nEpoch 17/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0351 \nEpoch 18/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0354 \nEpoch 19/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0362 \nEpoch 20/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0330 \nEpoch 21/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0323 \nEpoch 22/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0325 \nEpoch 23/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0332 \nEpoch 24/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0319 \nEpoch 25/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0360 \nEpoch 26/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0350 \nEpoch 27/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0339 \nEpoch 28/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0348 \nEpoch 29/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0346 \nEpoch 30/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0331 \nEpoch 31/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0348 \nEpoch 32/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0344 \nEpoch 33/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0329 \nEpoch 34/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0347 \nEpoch 35/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0333 \nEpoch 36/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0349 \nEpoch 37/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0328 \nEpoch 38/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0357 \nEpoch 39/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0350 \nEpoch 40/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0343 \nEpoch 41/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0336 \nEpoch 42/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0337 \nEpoch 43/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0357 \nEpoch 44/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0355 \nEpoch 45/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0344 \nEpoch 46/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0352 \nEpoch 47/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0349 \nEpoch 48/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0339 \nEpoch 49/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0338 \nEpoch 50/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0335 \nEpoch 51/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0316 \nEpoch 52/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0315 \nEpoch 53/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0333 \nEpoch 54/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0332 \nEpoch 55/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0329 \nEpoch 56/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0336 \nEpoch 57/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0324 \nEpoch 58/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0331 \nEpoch 59/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0338 \nEpoch 60/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0334 \nEpoch 61/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0344 \nEpoch 62/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0337 \nEpoch 63/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0336 \nEpoch 64/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0339 \nEpoch 65/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0337 \nEpoch 66/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0359 \nEpoch 67/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0335 \nEpoch 68/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0367 \nEpoch 69/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0369 \nEpoch 70/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0340 \nEpoch 71/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0314 \nEpoch 72/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0342 \nEpoch 73/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0346 \nEpoch 74/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0330 \nEpoch 75/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0341 \nEpoch 76/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0326 \nEpoch 77/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0340 \nEpoch 78/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0339 \nEpoch 79/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0349 \nEpoch 80/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0344 \nEpoch 81/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0341 \nEpoch 82/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0359 \nEpoch 83/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0345 \nEpoch 84/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0359 \nEpoch 85/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0362 \nEpoch 86/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0332 \nEpoch 87/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0326 \nEpoch 88/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0324 \nEpoch 89/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0338 \nEpoch 90/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0322 \nEpoch 91/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0324 \nEpoch 92/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0337 \nEpoch 93/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0326 \nEpoch 94/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0328 \nEpoch 95/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0348 \nEpoch 96/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0331 \nEpoch 97/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0334 \nEpoch 98/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0347 \nEpoch 99/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0336 \nEpoch 100/100\n\u001B[1m29/29\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0362 \n\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\nMean Squared Error: 0.03751425753688661\nR^2 Score: 0.012160642471464311\n     Actual  Predicted\n0  0.687500   0.443778\n1  0.375000   0.539223\n2  0.312500   0.554801\n3  0.687500   0.427065\n4  0.529412   0.419238\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
