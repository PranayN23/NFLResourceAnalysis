{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Player Performance Prediction (QB) - Transformer + Time2Vec\n",
                "\n",
                "This notebook implements a Transformer-based model with Time2Vec embeddings to predict future player performance (e.g., PFF Grade) based on historical data. \n",
                "\n",
                "## Architecture\n",
                "1. **Time2Vec Embedding**: Captures periodic and linear temporal patterns.\n",
                "2. **Transformer Encoder**: Captures long-range dependencies and interactions between features.\n",
                "3. **Regression Head**: Predicts the target metric."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: tensorflow in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (2.20.0)\n",
                        "Requirement already satisfied: pandas in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (2.1.1)\n",
                        "Requirement already satisfied: numpy in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (1.26.0)\n",
                        "Requirement already satisfied: scikit-learn in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (1.8.0)\n",
                        "Requirement already satisfied: matplotlib in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (3.8.0)\n",
                        "Requirement already satisfied: absl-py>=1.0.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
                        "Requirement already satisfied: astunparse>=1.6.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
                        "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (25.12.19)\n",
                        "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (0.7.0)\n",
                        "Requirement already satisfied: google_pasta>=0.1.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
                        "Requirement already satisfied: libclang>=13.0.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
                        "Requirement already satisfied: opt_einsum>=2.3.2 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
                        "Requirement already satisfied: packaging in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (26.0)\n",
                        "Requirement already satisfied: protobuf>=5.28.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (6.33.5)\n",
                        "Requirement already satisfied: requests<3,>=2.21.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
                        "Requirement already satisfied: setuptools in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (75.6.0)\n",
                        "Requirement already satisfied: six>=1.12.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (1.17.0)\n",
                        "Requirement already satisfied: termcolor>=1.1.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
                        "Requirement already satisfied: typing_extensions>=3.6.6 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (4.15.0)\n",
                        "Requirement already satisfied: wrapt>=1.11.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
                        "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (1.76.0)\n",
                        "Requirement already satisfied: tensorboard~=2.20.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (2.20.0)\n",
                        "Requirement already satisfied: keras>=3.10.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (3.13.2)\n",
                        "Requirement already satisfied: h5py>=3.11.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (3.15.1)\n",
                        "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.6.3)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
                        "Requirement already satisfied: markdown>=2.6.8 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10.1)\n",
                        "Requirement already satisfied: pillow in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (12.1.0)\n",
                        "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
                        "Requirement already satisfied: werkzeug>=1.0.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from pandas) (2025.3)\n",
                        "Requirement already satisfied: scipy>=1.10.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from scikit-learn) (1.11.3)\n",
                        "Requirement already satisfied: joblib>=1.3.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from scikit-learn) (1.5.3)\n",
                        "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
                        "Requirement already satisfied: contourpy>=1.0.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
                        "Requirement already satisfied: cycler>=0.10 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
                        "Requirement already satisfied: fonttools>=4.22.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from matplotlib) (4.61.1)\n",
                        "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
                        "Requirement already satisfied: pyparsing>=2.3.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from matplotlib) (3.3.2)\n",
                        "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
                        "Requirement already satisfied: rich in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow) (14.3.2)\n",
                        "Requirement already satisfied: namex in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
                        "Requirement already satisfied: optree in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
                        "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
                        "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
                        "Requirement already satisfied: mdurl~=0.1 in /Users/pranaynandkeolyar/Documents/NFLSalaryCap/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
                    ]
                }
            ],
            "source": [
                "# Install dependencies if not already installed\n",
                "!pip install tensorflow pandas numpy scikit-learn matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import r2_score\n",
                "import os\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Time2Vec Layer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Time2Vec(layers.Layer):\n",
                "    def __init__(self, kernel_size=1, **kwargs):\n",
                "        super(Time2Vec, self).__init__(**kwargs)\n",
                "        self.k = kernel_size\n",
                "    \n",
                "    def build(self, input_shape):\n",
                "        # weights: (k+1) inputs (1 for linear, k for periodic)\n",
                "        self.wb = self.add_weight(name='wb',\n",
                "                                shape=(input_shape[-1],),\n",
                "                                initializer='uniform',\n",
                "                                trainable=True)\n",
                "        self.wa = self.add_weight(name='wa',\n",
                "                                shape=(1, input_shape[-1], self.k),\n",
                "                                initializer='uniform',\n",
                "                                trainable=True)\n",
                "        self.ba = self.add_weight(name='ba',\n",
                "                                shape=(1, input_shape[-1], self.k),\n",
                "                                initializer='uniform',\n",
                "                                trainable=True)\n",
                "        super(Time2Vec, self).build(input_shape)\n",
                "\n",
                "    def call(self, inputs, **kwargs):\n",
                "        # inputs shape: (batch_size, time_steps, features)\n",
                "        # Linear term: wb * inputs\n",
                "        bias = self.wb * inputs\n",
                "        # Periodic term: sin(wa * inputs + ba)\n",
                "        pattern = tf.math.sin(tf.matmul(inputs, self.wa) + self.ba)\n",
                "        pattern = tf.reshape(pattern, (-1, inputs.shape[1], inputs.shape[2] * self.k))\n",
                "        return tf.concat([bias, pattern], axis=-1)\n",
                "\n",
                "    def compute_output_shape(self, input_shape):\n",
                "        return (input_shape[0], input_shape[1], input_shape[2] * (self.k + 1))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Transformer Block"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "class TransformerBlock(layers.Layer):\n",
                "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1, **kwargs):\n",
                "        super(TransformerBlock, self).__init__(**kwargs)\n",
                "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
                "        self.ffn = models.Sequential(\n",
                "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
                "        )\n",
                "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
                "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
                "        self.dropout1 = layers.Dropout(rate)\n",
                "        self.dropout2 = layers.Dropout(rate)\n",
                "\n",
                "    def call(self, inputs, training=False):\n",
                "        attn_output = self.att(inputs, inputs)\n",
                "        attn_output = self.dropout1(attn_output, training=training)\n",
                "        out1 = self.layernorm1(inputs + attn_output)\n",
                "        ffn_output = self.ffn(out1)\n",
                "        ffn_output = self.dropout2(ffn_output, training=training)\n",
                "        return self.layernorm2(out1 + ffn_output)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Loading & Sliding Window Generation\n",
                "\n",
                "We need to group by player and create sequences (e.g., Year 1-3 predicts Year 4)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Reading data from: ../../Grouped_Data/Grouped_QB.csv\n",
                        "Loaded Data Shape: (480, 43)\n",
                        "Columns: ['Unnamed: 0', 'Team', 'Year', 'Cap_Space', 'adjusted_value', 'Net EPA', 'Win %', 'franchise_id', 'aimed_passes', 'attempts', 'completions', 'touchdowns', 'interceptions', 'sacks', 'scrambles', 'first_downs', 'yards', 'dropbacks', 'drops', 'big_time_throws', 'turnover_worthy_plays', 'bats', 'declined_penalties', 'penalties', 'hit_as_threw', 'thrown_aways', 'spikes', 'accuracy_percent', 'completion_percent', 'btt_rate', 'twp_rate', 'drop_rate', 'qb_rating', 'sack_percent', 'pressure_to_sack_rate', 'avg_depth_of_target', 'avg_time_to_throw', 'ypa', 'def_gen_pressures', 'grades_hands_fumble', 'grades_offense', 'grades_pass', 'grades_run']\n",
                        "Years covered: 2010 - 2024\n"
                    ]
                },
                {
                    "ename": "KeyError",
                    "evalue": "\"Could not find a player identifier column. Available columns: ['Unnamed: 0', 'Team', 'Year', 'Cap_Space', 'adjusted_value', 'Net EPA', 'Win %', 'franchise_id', 'aimed_passes', 'attempts', 'completions', 'touchdowns', 'interceptions', 'sacks', 'scrambles', 'first_downs', 'yards', 'dropbacks', 'drops', 'big_time_throws', 'turnover_worthy_plays', 'bats', 'declined_penalties', 'penalties', 'hit_as_threw', 'thrown_aways', 'spikes', 'accuracy_percent', 'completion_percent', 'btt_rate', 'twp_rate', 'drop_rate', 'qb_rating', 'sack_percent', 'pressure_to_sack_rate', 'avg_depth_of_target', 'avg_time_to_throw', 'ypa', 'def_gen_pressures', 'grades_hands_fumble', 'grades_offense', 'grades_pass', 'grades_run']\"",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m     df.rename(columns={player_id_col: \u001b[33m'\u001b[39m\u001b[33mplayer\u001b[39m\u001b[33m'\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find a player identifier column. Available columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.columns.tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnique Players: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mplayer\u001b[39m\u001b[33m'\u001b[39m].nunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m df.sort_values(by=[\u001b[33m'\u001b[39m\u001b[33mplayer\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mYear\u001b[39m\u001b[33m'\u001b[39m], inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
                        "\u001b[31mKeyError\u001b[39m: \"Could not find a player identifier column. Available columns: ['Unnamed: 0', 'Team', 'Year', 'Cap_Space', 'adjusted_value', 'Net EPA', 'Win %', 'franchise_id', 'aimed_passes', 'attempts', 'completions', 'touchdowns', 'interceptions', 'sacks', 'scrambles', 'first_downs', 'yards', 'dropbacks', 'drops', 'big_time_throws', 'turnover_worthy_plays', 'bats', 'declined_penalties', 'penalties', 'hit_as_threw', 'thrown_aways', 'spikes', 'accuracy_percent', 'completion_percent', 'btt_rate', 'twp_rate', 'drop_rate', 'qb_rating', 'sack_percent', 'pressure_to_sack_rate', 'avg_depth_of_target', 'avg_time_to_throw', 'ypa', 'def_gen_pressures', 'grades_hands_fumble', 'grades_offense', 'grades_pass', 'grades_run']\""
                    ]
                }
            ],
            "source": [
                "# Load Data from the specified path\n",
                "data_path = '../../Grouped_Data/Grouped_QB.csv' \n",
                "if not os.path.exists(data_path):\n",
                "    # Attempt absolute path fallback\n",
                "    data_path = '/Users/pranaynandkeolyar/Documents/NFLSalaryCap/backend/Grouped_Data/Grouped_QB.csv'\n",
                "\n",
                "print(f\"Reading data from: {data_path}\")\n",
                "df = pd.read_csv(data_path)\n",
                "print(f\"Loaded Data Shape: {df.shape}\")\n",
                "print(f\"Columns: {df.columns.tolist()}\")  # Print columns to debug KeyError\n",
                "\n",
                "# Ensure 'Year' column exists and handle potential variations\n",
                "if 'year' in df.columns: \n",
                "    df.rename(columns={'year': 'Year'}, inplace=True)\n",
                "\n",
                "print(f\"Years covered: {df['Year'].min()} - {df['Year'].max()}\")\n",
                "\n",
                "# Check Player Identifier\n",
                "# The file might use 'Name', 'Player', or 'player'. \n",
                "possible_id_cols = ['player', 'Player', 'Name', 'name']\n",
                "player_id_col = None\n",
                "for col in possible_id_cols:\n",
                "    if col in df.columns:\n",
                "        player_id_col = col\n",
                "        break\n",
                "\n",
                "if player_id_col:\n",
                "    print(f\"Using player identifier column: {player_id_col}\")\n",
                "    df.rename(columns={player_id_col: 'player'}, inplace=True)\n",
                "else:\n",
                "    raise KeyError(f\"Could not find a player identifier column. Available columns: {df.columns.tolist()}\")\n",
                "\n",
                "print(f\"Unique Players: {df['player'].nunique()}\")\n",
                "df.sort_values(by=['player', 'Year'], inplace=True)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEQUENCE_LENGTH = 3  # Use 3 years of history to predict the next year\n",
                "\n",
                "# Update features based on Grouped_QB columns if needed. \n",
                "# Assuming similar structure but we will verify what's available.\n",
                "# Let's stick to the previous list but be robust if columns are missing.\n",
                "features = [\n",
                "    'Previous_twp_rate', \n",
                "    'Previous_ypa', \n",
                "    'Previous_qb_rating', \n",
                "    'Previous_grades_pass', \n",
                "    'Value_cap_space', \n",
                "    'Previous_PFF', \n",
                "    'Previous_AV'\n",
                "]\n",
                "target_col = 'Current_PFF'\n",
                "\n",
                "# Dynamic Feature checking\n",
                "available_features = [f for f in features if f in df.columns]\n",
                "if len(available_features) < len(features):\n",
                "    print(f\"Warning: Missing features. Using: {available_features}\")\n",
                "    features = available_features\n",
                "\n",
                "df_clean = df.dropna(subset=features + [target_col])\n",
                "\n",
                "# Normalize\n",
                "scaler = StandardScaler()\n",
                "df_clean[features] = scaler.fit_transform(df_clean[features])\n",
                "\n",
                "def create_sequences(dataset, seq_len, features, target):\n",
                "    X = []\n",
                "    y = []\n",
                "    \n",
                "    # Group by player\n",
                "    for player, group in dataset.groupby('player'):\n",
                "        group = group.sort_values('Year')\n",
                "        \n",
                "        if len(group) <= seq_len:\n",
                "            continue\n",
                "            \n",
                "        vals = group[features].values\n",
                "        targs = group[target].values\n",
                "        \n",
                "        for i in range(len(group) - seq_len):\n",
                "            X.append(vals[i:i+seq_len])\n",
                "            y.append(targs[i+seq_len])\n",
                "            \n",
                "    return np.array(X), np.array(y)\n",
                "\n",
                "# Create Datasets\n",
                "X, y = create_sequences(df_clean, SEQUENCE_LENGTH, features, target_col)\n",
                "print(f\"Generated Sequences Shape: X={X.shape}, y={y.shape}\")\n",
                "\n",
                "if len(X) == 0:\n",
                "    print(\"Error: Not enough history per player to create sequences of length\", SEQUENCE_LENGTH)\n",
                "else:\n",
                "    from sklearn.model_selection import train_test_split\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "    print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Build & Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_transformer_model(input_shape, head_size=32, num_heads=2, ff_dim=32, num_transformer_blocks=1, mlp_units=[64]):\n",
                "    inputs = layers.Input(shape=input_shape)\n",
                "    \n",
                "    x = Time2Vec(kernel_size=2)(inputs)\n",
                "    \n",
                "    for _ in range(num_transformer_blocks):\n",
                "        x = TransformerBlock(x.shape[-1], num_heads, ff_dim)(x)\n",
                "\n",
                "    x = layers.GlobalAveragePooling1D()(x)\n",
                "    \n",
                "    for dim in mlp_units:\n",
                "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
                "        x = layers.Dropout(0.2)(x)\n",
                "        \n",
                "    outputs = layers.Dense(1)(x)\n",
                "    \n",
                "    model = models.Model(inputs=inputs, outputs=outputs)\n",
                "    return model\n",
                "\n",
                "if len(X) > 0:\n",
                "    input_shape = (SEQUENCE_LENGTH, X_train.shape[2])\n",
                "    model = build_transformer_model(input_shape)\n",
                "    \n",
                "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
                "    model.summary()\n",
                "    \n",
                "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
                "\n",
                "    history = model.fit(\n",
                "        X_train, y_train,\n",
                "        epochs=200,\n",
                "        batch_size=16,\n",
                "        validation_split=0.2,\n",
                "        callbacks=[early_stopping],\n",
                "        verbose=1\n",
                "    )\n",
                "    \n",
                "    # Eval\n",
                "    test_pred = model.predict(X_test).flatten()\n",
                "    print(f\"Test RÂ²: {r2_score(y_test, test_pred):.4f}\")\n",
                "    \n",
                "    plt.scatter(y_test, test_pred)\n",
                "    plt.xlabel('Actual')\n",
                "    plt.ylabel('Predicted')\n",
                "    plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
