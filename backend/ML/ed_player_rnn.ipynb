{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/achintiii/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edge Position RNN Training (2010-2024)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Edge Position RNN Training (2010-2024)\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to MongoDB and loading edge position data...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'MongoClient' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Load the data from MongoDB\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_edge_data_from_mongodb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mload_edge_data_from_mongodb\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# MongoDB connection\u001b[39;00m\n\u001b[1;32m      9\u001b[0m mongo_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmongodb+srv://pranaynandkeolyar:nfl@cluster0.4nbxj.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mMongoClient\u001b[49m(mongo_uri)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Connect to ED database\u001b[39;00m\n\u001b[1;32m     13\u001b[0m pos_db \u001b[38;5;241m=\u001b[39m client[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mED\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MongoClient' is not defined"
          ]
        }
      ],
      "source": [
        "def load_edge_data_from_mongodb():\n",
        "    \"\"\"\n",
        "    Load edge position data from MongoDB.\n",
        "    Returns the most comprehensive dataset available.\n",
        "    \"\"\"\n",
        "    print(\"Connecting to MongoDB and loading edge position data...\")\n",
        "    \n",
        "    # MongoDB connection\n",
        "    mongo_uri = \"mongodb+srv://pranaynandkeolyar:nfl@cluster0.4nbxj.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "    client = MongoClient(mongo_uri)\n",
        "    \n",
        "    # Connect to ED database\n",
        "    pos_db = client['ED']\n",
        "    all_teams = pos_db.list_collection_names()\n",
        "    \n",
        "    print(f\"Found {len(all_teams)} team collections in ED database\")\n",
        "    \n",
        "    # Collect all data from all teams\n",
        "    all_data = []\n",
        "    for team in all_teams:\n",
        "        collection = pos_db[team]\n",
        "        cursor = collection.find({'Year': {'$exists': True}})\n",
        "        for doc in cursor:\n",
        "            player_data = {k: v for k, v in doc.items() if k != '_id'}\n",
        "            all_data.append(player_data)\n",
        "    \n",
        "    df = pd.DataFrame(all_data)\n",
        "    print(f\"âœ… Loaded {len(df)} records from MongoDB\")\n",
        "    \n",
        "    if len(df) > 0:\n",
        "        print(f\"Years available: {sorted(df['Year'].unique())}\")\n",
        "        print(f\"Columns in dataset: {len(df.columns)} columns\")\n",
        "        \n",
        "        # Filter for minimum snap counts (similar to QB filtering)\n",
        "        if 'snap_counts_defense' in df.columns:\n",
        "            df = df[df['snap_counts_defense'] >= 100]\n",
        "            print(f\"Rows after filtering for >=100 defensive snaps: {len(df)}\")\n",
        "    else:\n",
        "        print(\"âŒ No edge data found in MongoDB!\")\n",
        "        return None\n",
        "    \n",
        "    client.close()\n",
        "    return df\n",
        "\n",
        "# Load the data from MongoDB\n",
        "df = load_edge_data_from_mongodb()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display basic information about the dataset\n",
        "if df is not None:\n",
        "    print(\"Dataset Info:\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Columns: {list(df.columns)}\")\n",
        "    print(f\"\\nFirst 5 rows:\")\n",
        "    print(df.head())\n",
        "    \n",
        "    print(f\"\\nYear distribution:\")\n",
        "    print(df['Year'].value_counts().sort_index())\n",
        "    \n",
        "    print(f\"\\nMissing values per column:\")\n",
        "    print(df.isnull().sum().sort_values(ascending=False))\n",
        "else:\n",
        "    print(\"No data loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_edge_features(df, target_metric='grades_defense'):\n",
        "    \"\"\"\n",
        "    Prepare features and target for edge position RNN model.\n",
        "    \"\"\"\n",
        "    print(f\"\\nPreparing features for target metric: {target_metric}\")\n",
        "    \n",
        "    # Define feature columns for edge position\n",
        "    feature_columns = [\n",
        "        'age', 'snap_counts_defense', 'assists', 'batted_passes', 'forced_fumbles',\n",
        "        'grades_defense', 'grades_pass_rush_defense', 'grades_run_defense',\n",
        "        'hits', 'hurries', 'missed_tackle_rate', 'sacks', 'stops', 'tackles',\n",
        "        'tackles_for_loss', 'total_pressures'\n",
        "    ]\n",
        "    \n",
        "    # Check which columns exist in the dataframe\n",
        "    available_features = [col for col in feature_columns if col in df.columns]\n",
        "    \n",
        "    if not available_features:\n",
        "        print(\"Warning: No edge-specific features found, using basic features\")\n",
        "        available_features = ['age', 'sacks', 'tackles']\n",
        "    \n",
        "    print(f\"Using features: {available_features}\")\n",
        "    \n",
        "    # Check if target metric exists\n",
        "    if target_metric not in df.columns:\n",
        "        print(f\"Warning: Target metric '{target_metric}' not found in data\")\n",
        "        # Try alternative metrics\n",
        "        alternatives = ['sacks', 'total_pressures', 'tackles', 'grades_pass_rush_defense']\n",
        "        for alt in alternatives:\n",
        "            if alt in df.columns:\n",
        "                target_metric = alt\n",
        "                print(f\"Using alternative target metric: {target_metric}\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"âŒ No suitable target metric found\")\n",
        "            return None, None, None\n",
        "    \n",
        "    # Filter data to years 2010-2024 and remove rows with missing target values\n",
        "    df_filtered = df[(df['Year'] >= 2010) & (df['Year'] <= 2024)].copy()\n",
        "    df_filtered = df_filtered.dropna(subset=[target_metric])\n",
        "    \n",
        "    print(f\"Filtered data: {len(df_filtered)} records\")\n",
        "    print(f\"Years in filtered data: {sorted(df_filtered['Year'].unique())}\")\n",
        "    \n",
        "    # Prepare features and target\n",
        "    features = df_filtered[available_features].fillna(0)\n",
        "    target = df_filtered[target_metric]\n",
        "    \n",
        "    return features, target, df_filtered\n",
        "\n",
        "# Prepare data for grades_defense metric\n",
        "features, target, df_filtered = prepare_edge_features(df, 'grades_defense')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sequences for RNN (similar to QB RNN approach)\n",
        "def make_edge_sequences(sub_df, feature_columns, target_column=\"grades_defense\", seq_len=3):\n",
        "    \"\"\"\n",
        "    Create sequences for RNN training from edge position data.\n",
        "    \"\"\"\n",
        "    sequences, targets, info = [], [], []\n",
        "    player_groups = sub_df.groupby('player')\n",
        "\n",
        "    for player, group in player_groups:\n",
        "        group = group.sort_values('Year')\n",
        "        for i in range(len(group) - seq_len):\n",
        "            target_year = group.iloc[i + seq_len]['Year']\n",
        "            seq = group.iloc[i:i+seq_len][feature_columns].values\n",
        "            target = group.iloc[i+seq_len][target_column]\n",
        "            # Skip sequences if there are any NaNs\n",
        "            if np.isnan(seq).any() or pd.isna(target):\n",
        "                continue\n",
        "            sequences.append(seq)\n",
        "            targets.append(target)\n",
        "            info.append({\n",
        "                'player': player,\n",
        "                'team': group.iloc[i+seq_len]['Team'],\n",
        "                'target_year': target_year\n",
        "            })\n",
        "    return np.array(sequences), np.array(targets), pd.DataFrame(info)\n",
        "\n",
        "# Create sequences for training and testing\n",
        "print(\"Creating sequences for RNN...\")\n",
        "\n",
        "# Define sequence parameters\n",
        "seq_len = 3\n",
        "first_predict_year = 2015\n",
        "train_year_end = 2019\n",
        "val_years = [2020, 2021]\n",
        "test_year_start = 2022\n",
        "\n",
        "# Get feature column names\n",
        "feature_column_names = features.columns.tolist()\n",
        "\n",
        "# Training sequences\n",
        "train_df_full = df_filtered[df_filtered['Year'] < min(val_years)].copy()\n",
        "X_train, y_train, train_info = make_edge_sequences(train_df_full, feature_column_names,\n",
        "                                                  target_column='grades_defense', seq_len=seq_len)\n",
        "\n",
        "# Validation sequences\n",
        "val_df_full = df_filtered[df_filtered['Year'] <= max(val_years)].copy()\n",
        "X_val, y_val, val_info = make_edge_sequences(val_df_full, feature_column_names,\n",
        "                                            target_column='grades_defense', seq_len=seq_len)\n",
        "\n",
        "# Test sequences\n",
        "test_df_full = df_filtered[df_filtered['Year'] <= df_filtered['Year'].max()].copy()\n",
        "X_test, y_test, test_info = make_edge_sequences(test_df_full, feature_column_names,\n",
        "                                               target_column='grades_defense', seq_len=seq_len)\n",
        "\n",
        "print(f\"Training sequences: {X_train.shape}\")\n",
        "print(f\"Validation sequences: {X_val.shape}\")\n",
        "print(f\"Test sequences: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create 75-25 train-test split\n",
        "print(\"Creating 75-25 train-test split...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, target, test_size=0.25, random_state=42, stratify=None\n",
        ")\n",
        "\n",
        "print(f\"Training set: {len(X_train)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n",
        "print(f\"Training features shape: {X_train.shape}\")\n",
        "print(f\"Test features shape: {X_test.shape}\")\n",
        "\n",
        "# Display feature statistics\n",
        "print(f\"\\nFeature statistics:\")\n",
        "print(X_train.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize features\n",
        "print(\"Standardizing features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape for RNN input (samples, time steps, features)\n",
        "# For single time step, we'll use 1 as the time dimension\n",
        "X_train_reshaped = X_train_scaled.reshape(\n",
        "    (X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
        ")\n",
        "X_test_reshaped = X_test_scaled.reshape(\n",
        "    (X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        ")\n",
        "\n",
        "print(f\"Training data shape: {X_train_reshaped.shape}\")\n",
        "print(f\"Test data shape: {X_test_reshaped.shape}\")\n",
        "print(f\"Number of features: {X_train_reshaped.shape[2]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define attention mechanism (similar to QB RNN)\n",
        "def attention_layer(inputs):\n",
        "    \"\"\"Simple attention mechanism for RNN.\"\"\"\n",
        "    attention = tf.keras.layers.Dense(1, activation='tanh')(inputs)\n",
        "    attention = tf.keras.layers.Softmax(axis=1)(attention)\n",
        "    return tf.reduce_sum(attention, axis=1)\n",
        "\n",
        "print(\"Attention mechanism defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and train RNN model\n",
        "print(\"Creating RNN model...\")\n",
        "\n",
        "# Model hyperparameters\n",
        "learning_rate = 0.001\n",
        "lstm_size = 64\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(\n",
        "        lstm_size, \n",
        "        activation='relu', \n",
        "        input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), \n",
        "        return_sequences=True\n",
        "    ),\n",
        "    tf.keras.layers.Lambda(attention_layer),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss='mean_squared_error'\n",
        ")\n",
        "\n",
        "# Display model summary\n",
        "print(\"Model Summary:\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Training RNN model...\")\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train, \n",
        "    epochs=100, \n",
        "    batch_size=32, \n",
        "    validation_split=0.2, \n",
        "    callbacks=[early_stopping], \n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model and calculate statistics\n",
        "print(\"Evaluating model...\")\n",
        "\n",
        "# Make predictions\n",
        "train_predictions = model.predict(X_train_reshaped, verbose=0).flatten()\n",
        "test_predictions = model.predict(X_test_reshaped, verbose=0).flatten()\n",
        "\n",
        "# Calculate RÂ² scores\n",
        "train_r2 = r2_score(y_train, train_predictions)\n",
        "test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "# Calculate other metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "train_mse = mean_squared_error(y_train, train_predictions)\n",
        "test_mse = mean_squared_error(y_test, test_predictions)\n",
        "train_mae = mean_absolute_error(y_train, train_predictions)\n",
        "test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "\n",
        "# Print results\n",
        "print(\"=\" * 60)\n",
        "print(\"MODEL PERFORMANCE STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Training Set:\")\n",
        "print(f\"  RÂ² Score: {train_r2:.4f}\")\n",
        "print(f\"  MSE: {train_mse:.4f}\")\n",
        "print(f\"  MAE: {train_mae:.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(train_mse):.4f}\")\n",
        "print(f\"\\nTest Set:\")\n",
        "print(f\"  RÂ² Score: {test_r2:.4f}\")\n",
        "print(f\"  MSE: {test_mse:.4f}\")\n",
        "print(f\"  MAE: {test_mae:.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(test_mse):.4f}\")\n",
        "\n",
        "print(f\"\\nTraining samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "print(f\"Total features used: {X_train.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_train, train_predictions, alpha=0.5, label='Training')\n",
        "plt.scatter(y_test, test_predictions, alpha=0.5, label='Test')\n",
        "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ðŸ“Š Visualization complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model_path = 'ed_rnn_model_grades_defense_2010_2024.h5'\n",
        "model.save(model_path)\n",
        "print(f\"âœ… Model saved as: {model_path}\")\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"âœ… Edge Position RNN Training Complete!\")\n",
        "print(f\"ðŸ“Š Dataset: {len(df_filtered)} records (2010-2024)\")\n",
        "print(f\"ðŸ”§ Model: LSTM + Attention\")\n",
        "print(f\"ðŸ“ˆ Best Test RÂ² Score: {test_r2:.4f}\")\n",
        "print(f\"ðŸ’¾ Model saved: {model_path}\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
