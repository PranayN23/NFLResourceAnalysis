{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Edge Position RNN Training (2010-2024)\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_edge_data():\n",
        "    \"\"\"\n",
        "    Load edge position data from CSV files.\n",
        "    Returns the most comprehensive dataset available.\n",
        "    \"\"\"\n",
        "    print(\"Loading edge position data from CSV files...\")\n",
        "    \n",
        "    # Try to load the main ED.csv file first (most comprehensive)\n",
        "    try:\n",
        "        df = pd.read_csv('ED.csv')\n",
        "        print(f\"âœ… Loaded ED.csv: {len(df)} records\")\n",
        "        print(f\"Years available: {sorted(df['Year'].unique())}\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(\"ED.csv not found, trying ED_no_cap.csv...\")\n",
        "        \n",
        "    try:\n",
        "        df = pd.read_csv('ED_no_cap.csv')\n",
        "        print(f\"âœ… Loaded ED_no_cap.csv: {len(df)} records\")\n",
        "        print(f\"Years available: {sorted(df['Year'].unique())}\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(\"ED_no_cap.csv not found, trying EDPFF.csv...\")\n",
        "        \n",
        "    try:\n",
        "        df = pd.read_csv('EDPFF.csv')\n",
        "        print(f\"âœ… Loaded EDPFF.csv: {len(df)} records\")\n",
        "        print(f\"Years available: {sorted(df['Year'].unique())}\")\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print(\"âŒ No edge data files found!\")\n",
        "        return None\n",
        "\n",
        "# Load the data\n",
        "df = load_edge_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display basic information about the dataset\n",
        "if df is not None:\n",
        "    print(\"Dataset Info:\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Columns: {list(df.columns)}\")\n",
        "    print(f\"\\nFirst 5 rows:\")\n",
        "    print(df.head())\n",
        "    \n",
        "    print(f\"\\nYear distribution:\")\n",
        "    print(df['Year'].value_counts().sort_index())\n",
        "    \n",
        "    print(f\"\\nMissing values per column:\")\n",
        "    print(df.isnull().sum().sort_values(ascending=False))\n",
        "else:\n",
        "    print(\"No data loaded!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_edge_features(df, target_metric='grades_defense'):\n",
        "    \"\"\"\n",
        "    Prepare features and target for edge position RNN model.\n",
        "    \"\"\"\n",
        "    print(f\"\\nPreparing features for target metric: {target_metric}\")\n",
        "    \n",
        "    # Define feature columns for edge position\n",
        "    feature_columns = [\n",
        "        'age', 'snap_counts_defense', 'assists', 'batted_passes', 'forced_fumbles',\n",
        "        'grades_defense', 'grades_pass_rush_defense', 'grades_run_defense',\n",
        "        'hits', 'hurries', 'missed_tackle_rate', 'sacks', 'stops', 'tackles',\n",
        "        'tackles_for_loss', 'total_pressures'\n",
        "    ]\n",
        "    \n",
        "    # Check which columns exist in the dataframe\n",
        "    available_features = [col for col in feature_columns if col in df.columns]\n",
        "    \n",
        "    if not available_features:\n",
        "        print(\"Warning: No edge-specific features found, using basic features\")\n",
        "        available_features = ['age', 'sacks', 'tackles']\n",
        "    \n",
        "    print(f\"Using features: {available_features}\")\n",
        "    \n",
        "    # Check if target metric exists\n",
        "    if target_metric not in df.columns:\n",
        "        print(f\"Warning: Target metric '{target_metric}' not found in data\")\n",
        "        # Try alternative metrics\n",
        "        alternatives = ['sacks', 'total_pressures', 'tackles', 'grades_pass_rush_defense']\n",
        "        for alt in alternatives:\n",
        "            if alt in df.columns:\n",
        "                target_metric = alt\n",
        "                print(f\"Using alternative target metric: {target_metric}\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"âŒ No suitable target metric found\")\n",
        "            return None, None, None\n",
        "    \n",
        "    # Filter data to years 2010-2024 and remove rows with missing target values\n",
        "    df_filtered = df[(df['Year'] >= 2010) & (df['Year'] <= 2024)].copy()\n",
        "    df_filtered = df_filtered.dropna(subset=[target_metric])\n",
        "    \n",
        "    print(f\"Filtered data: {len(df_filtered)} records\")\n",
        "    print(f\"Years in filtered data: {sorted(df_filtered['Year'].unique())}\")\n",
        "    \n",
        "    # Prepare features and target\n",
        "    features = df_filtered[available_features].fillna(0)\n",
        "    target = df_filtered[target_metric]\n",
        "    \n",
        "    return features, target, df_filtered\n",
        "\n",
        "# Prepare data for grades_defense metric\n",
        "features, target, df_filtered = prepare_edge_features(df, 'grades_defense')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create 75-25 train-test split\n",
        "print(\"Creating 75-25 train-test split...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, target, test_size=0.25, random_state=42, stratify=None\n",
        ")\n",
        "\n",
        "print(f\"Training set: {len(X_train)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n",
        "print(f\"Training features shape: {X_train.shape}\")\n",
        "print(f\"Test features shape: {X_test.shape}\")\n",
        "\n",
        "# Display feature statistics\n",
        "print(f\"\\nFeature statistics:\")\n",
        "print(X_train.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize features\n",
        "print(\"Standardizing features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape for RNN input (samples, time steps, features)\n",
        "# For single time step, we'll use 1 as the time dimension\n",
        "X_train_reshaped = X_train_scaled.reshape(\n",
        "    (X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
        ")\n",
        "X_test_reshaped = X_test_scaled.reshape(\n",
        "    (X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
        ")\n",
        "\n",
        "print(f\"Training data shape: {X_train_reshaped.shape}\")\n",
        "print(f\"Test data shape: {X_test_reshaped.shape}\")\n",
        "print(f\"Number of features: {X_train_reshaped.shape[2]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define attention mechanism (similar to QB RNN)\n",
        "def attention_layer(inputs):\n",
        "    \"\"\"Simple attention mechanism for RNN.\"\"\"\n",
        "    attention = tf.keras.layers.Dense(1, activation='tanh')(inputs)\n",
        "    attention = tf.keras.layers.Softmax(axis=1)(attention)\n",
        "    return tf.reduce_sum(attention, axis=1)\n",
        "\n",
        "print(\"Attention mechanism defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and train RNN model\n",
        "print(\"Creating RNN model...\")\n",
        "\n",
        "# Model hyperparameters\n",
        "learning_rate = 0.001\n",
        "lstm_size = 64\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(\n",
        "        lstm_size, \n",
        "        activation='relu', \n",
        "        input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), \n",
        "        return_sequences=True\n",
        "    ),\n",
        "    tf.keras.layers.Lambda(attention_layer),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "    loss='mean_squared_error'\n",
        ")\n",
        "\n",
        "# Display model summary\n",
        "print(\"Model Summary:\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "print(\"Training RNN model...\")\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train_reshaped, y_train, \n",
        "    epochs=100, \n",
        "    batch_size=32, \n",
        "    validation_split=0.2, \n",
        "    callbacks=[early_stopping], \n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model and calculate statistics\n",
        "print(\"Evaluating model...\")\n",
        "\n",
        "# Make predictions\n",
        "train_predictions = model.predict(X_train_reshaped, verbose=0).flatten()\n",
        "test_predictions = model.predict(X_test_reshaped, verbose=0).flatten()\n",
        "\n",
        "# Calculate RÂ² scores\n",
        "train_r2 = r2_score(y_train, train_predictions)\n",
        "test_r2 = r2_score(y_test, test_predictions)\n",
        "\n",
        "# Calculate other metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "train_mse = mean_squared_error(y_train, train_predictions)\n",
        "test_mse = mean_squared_error(y_test, test_predictions)\n",
        "train_mae = mean_absolute_error(y_train, train_predictions)\n",
        "test_mae = mean_absolute_error(y_test, test_predictions)\n",
        "\n",
        "# Print results\n",
        "print(\"=\" * 60)\n",
        "print(\"MODEL PERFORMANCE STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Training Set:\")\n",
        "print(f\"  RÂ² Score: {train_r2:.4f}\")\n",
        "print(f\"  MSE: {train_mse:.4f}\")\n",
        "print(f\"  MAE: {train_mae:.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(train_mse):.4f}\")\n",
        "print(f\"\\nTest Set:\")\n",
        "print(f\"  RÂ² Score: {test_r2:.4f}\")\n",
        "print(f\"  MSE: {test_mse:.4f}\")\n",
        "print(f\"  MAE: {test_mae:.4f}\")\n",
        "print(f\"  RMSE: {np.sqrt(test_mse):.4f}\")\n",
        "\n",
        "print(f\"\\nTraining samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "print(f\"Total features used: {X_train.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(y_train, train_predictions, alpha=0.5, label='Training')\n",
        "plt.scatter(y_test, test_predictions, alpha=0.5, label='Test')\n",
        "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ðŸ“Š Visualization complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model_path = 'ed_rnn_model_grades_defense_2010_2024.h5'\n",
        "model.save(model_path)\n",
        "print(f\"âœ… Model saved as: {model_path}\")\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"âœ… Edge Position RNN Training Complete!\")\n",
        "print(f\"ðŸ“Š Dataset: {len(df_filtered)} records (2010-2024)\")\n",
        "print(f\"ðŸ”§ Model: LSTM + Attention\")\n",
        "print(f\"ðŸ“ˆ Best Test RÂ² Score: {test_r2:.4f}\")\n",
        "print(f\"ðŸ’¾ Model saved: {model_path}\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
